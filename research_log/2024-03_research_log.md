#### 2024-03-01
- Make Github and study how to use
- KITTI Dataset Setting [ğŸ”—](../LiDAR_Object_Detection/PointPillars/README.md#datasets)
- Customize python codes and settings [ğŸ”—](../LiDAR_Object_Detection/PointPillars/)
- Progress training with downloaded datasets [ğŸ”—](../LiDAR_Object_Detection/PointPillars/README.md#compile)

#### 2024-03-04
- Compare the pretrained model with the model I trained
- Pretrained model's performance is better than I did
- Progress evalutation, test and visualization [:link:](../LiDAR_Object_Detection/PointPillars/README.md#evaluation)

#### 2024-03-05
- ***<U>3D LiDAR Object Detectionì˜ ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ í™œìš©í•´ì•¼ í• ì§€ëŠ” ì¢€ ë” ê³ ë¯¼í•´ë³¼ê²ƒ..</U>***
- ì§€ê¸ˆê¹Œì§€ ë– ì˜¤ë¥¸ ìƒê°ì€ ì•„ë˜ì™€ ê°™ë‹¤
    
    1. My Subjective thoughts (Eliminate feasibility) # ì‹¤í˜„ê°€ëŠ¥ì„± ë°°ì œ
        - Object Detection with LiDAR and Camera simultaneously and separately
        - Generate each accuracy result as a list
        - Create a new list from each of the two lists via dot product
        - Normalize the new list to generate the final accuracy list

        ì´ë ‡ê²Œ ë§Œë“¤ì–´ì§„ final accuracy listê°€ ê¸°ì¡´ì˜ ê°ê°ì˜ accuracy listì™€ ë¹„êµí•´ì„œ ì–´ë– í• ì§€ í•œë²ˆ ì‹œë„..!
        - ë¹„ê°€ì˜¤ê±°ë‚˜, íë¦¿í•  ë•Œ final accuracy listê°€ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ë©´ ì„±ê³µì ì¸ ì‹œë„

        ë˜ ë‹¤ë¥¸ ë°©ë²• : ë‚ ì”¨ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ë‘ì–´ two accuracy list dot product
        - ë¬¸ì œì  : ê°€ì¤‘ì¹˜ë¥¼ ì–´ë–»ê²Œ ë©”ê¸¸ ê²ƒì¸ì§€
            - *<U>ë‚ ì”¨ì— ë”°ë¼ ì¤„ ìˆ˜ ìˆëŠ” standardê°€ ì¡´ì¬í•˜ëŠ”ì§€ì•„ë‹ˆë©´ ì´ê±¸(?) ì—°êµ¬.. ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ ì°¾ì•„ë³´ê¸°</U>*

    2. LiDAR-Camera Calibration
        - LiDAR-Camera Calibrationì„ ì§„í–‰ (ì•Œê³ ë¦¬ì¦˜ ë¯¸ì •)
        - ì´ë¥¼ ì‚¬ìš©í•´ object detection accuracy í–¥ìƒ í™•ì¸ (ê·¸ëƒ¥ í•´ë³´ëŠ” ëŠë‚Œ)

    3. Manipulator Robot
        - Robot armì— cameraê°€ ì¥ì°©ë˜ë©´ ì´ë¥¼ í™œìš©í•´ ë³¼ ë°©ë²• ìƒê°
            - Basic : camera object detectionê¸°ë°˜ìœ¼ë¡œ robot arm ì¡°ì¢…
            - Known environment ì—¬ëŸ¬ ë¯¸ì…˜ ìˆ˜í–‰
                1. ë¬¼ê±´ì„ ì°¾ì„ë•Œê¹Œì§€ SLAMì£¼í–‰
                2. ë¬¼ê±´ì„ ì°¾ìœ¼ë©´ robot armì„ ì¡°ì¢…í•´ì„œ ë¬¼ì²´ë¥¼ ë“¤ê±°ë‚˜ í•˜ëŠ” mission
                3. í–‰ë™ ì´í›„ ë‹¤ì‹œ ì›ë˜ ìë¦¬ë¡œ ëŒì•„ì˜¤ê¸°
    
    4. LiDAR PCD Structure study
        - VoxelNet[:link:](https://arxiv.org/abs/1711.06396), PointNet++[:link:](https://arxiv.org/abs/1706.02413)
        - Study the concept, then apply with the algorithm


#### 2024-03-06
- Study how to use YOLOv8 [:link:](../Camera_Object_Detection/YOLOv8/README.md#reference)
- Performance experiments with all pretrained models [:link:](../Camera_Object_Detection/YOLOv8/README.md#model-test)
    - I put first priority on **Real-time**
    - LiDAR Object Detection ì½”ë“œê°€ ì™„ì„±ë˜ë©´ ë°˜ë³µì ì¸ ì‹¤í—˜ìœ¼ë¡œ ì ì ˆí•œ pretrained model ì„ íƒ
- Up to now progress [:link:](../Camera_Object_Detection/YOLOv8/README.md#progress)

#### 2024-03-07 ~ 2024-03-12 (ì˜ˆì •)
- Coding for ***Extracting*** Camera Object Detection accuracy list
- Coding for ***Extracting*** LiDAR Object Detection accuracy list (Difficult..)


#### TODO
- Camera, Lidar ê°ê° Detection ê°€ëŠ¥í•˜ë„ë¡ ì½”ë“œ ì‘ì„±
- Calibration ê³µë¶€
    - ìë™ìœ¼ë¡œ calibration ê°€ëŠ¥í•œ ì•Œê³ ë¦¬ì¦˜ ë¨¼ì € í•´ë³¼ ê²ƒ
        - camera, lidarê°€ ì¥ì°©ë˜ì–´ rosbag recordí•œ ë°ì´í„°ì— ëŒ€í•´ì„œ ìë™ìœ¼ë¡œ calibration ê°’ì„ êµ¬í•´ì£¼ëŠ”ì§€
- ì´í›„ ë‘ ì„¼ì„œë¥¼ ì–´ë–»ê²Œ í•©ì¹  ê²ƒì¸ì§€ .... 
    - ê¸°ê³„ê´€ 107ì— ì¡´ì¬í•˜ëŠ” ì°¨ëŸ‰ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•´ì„œ ë°ì´í„°ì…‹ í™•ë³´(?)
        - í•˜ë‚˜ì˜ í™˜ê²½ì—ì„œ ê³ ì •ëœ ë‘ ì„¼ì„œë¥¼ í™œìš©í•œ ë°ì´í„° ìˆ˜ì§‘ 
    - ì•„ë‹ˆë©´ 
- Lidar Segmentation (ë‚˜ì¤‘ì—)
